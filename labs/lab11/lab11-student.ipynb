{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Time Series Analysis\n",
    "\n",
    "## Week 10: Spectral Gaussian Processes Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Places where you are supposed to fill in code are marked\n",
    "\n",
    "    #\n",
    "    # TODO: some instructions\n",
    "    # \n",
    "    \n",
    "The rest of the code we will run and discuss if time permits, otherwise try it out at home and try to answer the questions mentioned in the text boxes for yourself.\n",
    "\n",
    "You will need to install a new package:\n",
    "\n",
    "    pyGPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please turn in the code before 12/12/2018 5:20pm. \n",
    "\n",
    "### Your work will be evaluated based on the code and plots. You don't need to write down your answers to other questions in the text blocks, just think them over.\n",
    "\n",
    "### Title your submission file `lab11-student-[YOUR NET ID].ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyGPs\n",
    "import GPy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as spdist\n",
    "\n",
    "# Patch of initSMhypers(self, x, y) in pyGPs\n",
    "def initSMhypers(model, x, y):\n",
    "    x = np.atleast_2d(x)\n",
    "    y = np.atleast_2d(y)\n",
    "    (n, D) = x.shape\n",
    "    Q = model.covfunc.para[0]\n",
    "    w = np.zeros(Q)\n",
    "    m = np.zeros((D, Q))\n",
    "    s = np.zeros((D, Q))\n",
    "    w[:] = np.std(y) / Q\n",
    "    hypinit = np.zeros(Q + 2 * D * Q)\n",
    "\n",
    "    for i in range(D):\n",
    "        # Calculate distances\n",
    "        xslice = np.atleast_2d(x[:, i]).T\n",
    "        d2 = spdist.cdist(xslice, xslice, 'sqeuclidean')\n",
    "        if n > 1:\n",
    "            d2[d2 == 0] = d2[0, 1]\n",
    "        else:\n",
    "            d2[d2 == 0] = 1\n",
    "        minshift = np.min(np.min(np.sqrt(d2)))\n",
    "        nyquist = 0.5 / minshift\n",
    "        m[i, :] = nyquist * np.random.ranf((1, Q))\n",
    "        maxshift = np.max(np.max(np.sqrt(d2)))\n",
    "        s[i, :] = 1. / np.abs(maxshift * np.random.ranf((1, Q)))\n",
    "    hypinit[:Q] = np.log(w)\n",
    "    hypinit[Q + np.arange(0, Q * D)] = np.log(m[0, :]).T\n",
    "    hypinit[Q + Q * D + np.arange(0, Q * D)] = np.log(s[0, :]).T\n",
    "    model.covfunc.hyp = list(hypinit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer_plot(x, mu, std):\n",
    "    plt.plot(x, mu, c='#003300', label='Mean')\n",
    "    plt.plot(x, mu + std, c='#339933', label='One Standard Deviation')\n",
    "    plt.plot(x, mu - std, c='#339933')\n",
    "    plt.plot(x, mu + 2 * std, c='#9fdf9f', label='Two Standard Deviations')\n",
    "    plt.plot(x, mu - 2 * std, c='#9fdf9f')\n",
    "    plt.fill_between(x, mu, mu + std, color='#d9f2d9')\n",
    "    plt.fill_between(x, mu, mu - std, color='#d9f2d9')\n",
    "    plt.fill_between(x, mu + std, mu + 2 * std, color='#ecf9ec')\n",
    "    plt.fill_between(x, mu - std, mu - 2 * std, color='#ecf9ec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Look at the Data\n",
    "\n",
    "In this assignment, you will recreate Figure 1 of the paper \"Gaussian Process Kernels for Pattern Discovery and Extrapolation\" [Wilson, Adams] where spectral mixture kernels where introduced. This uses data measuring CO2 concentration collected at an observatory in Hawaii. Let's take a look at the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "co2_df = pd.read_csv('../../data/co2.csv', delim_whitespace=True, comment='#', header=None)\n",
    "# Truncate to avoid some misread points; this will start around 1985:\n",
    "X_CO2 = co2_df[2][314:]\n",
    "Y_CO2 = co2_df[3][314:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(X_CO2, Y_CO2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will divide this into training and test data, cutting off at 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_CO2_train = X_CO2[X_CO2 <= 2010]\n",
    "X_CO2_test = X_CO2[X_CO2 > 2010]\n",
    "\n",
    "num_train_points = X_CO2_train.shape[0]\n",
    "num_test_points = X_CO2_test.shape[0]\n",
    "\n",
    "Y_CO2_train = Y_CO2[:num_train_points]\n",
    "Y_CO2_test = Y_CO2[num_train_points:]\n",
    "\n",
    "X_CO2_train = X_CO2_train.reshape((num_train_points, 1))\n",
    "X_CO2_test = X_CO2_test.reshape((num_test_points, 1))\n",
    "Y_CO2_train = Y_CO2_train.reshape((num_train_points, 1))\n",
    "Y_CO2_test = Y_CO2_test.reshape((num_test_points, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kernel = GPy.kern.RBF(input_dim=1, variance=1., lengthscale=1.)\n",
    "m_reg = GPy.models.GPRegression(X_CO2_train, Y_CO2_train, kernel)\n",
    "_ = m_reg.optimize()\n",
    "_ = m_reg.plot(plot_density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean, var = m_reg.predict(X_CO2_test)\n",
    "layer_plot(X_CO2_test[:, 0], mean[:, 0], np.sqrt(var)[:, 0])\n",
    "plt.plot(X_CO2_test, Y_CO2_test, c='black', label='True Values', linewidth=3)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terrible!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Spectral Mixture Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how we run prediction with a spectral mixture model. The parameter `Q` controls how many components of the gaussian mixture are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kernel = pyGPs.cov.SM(Q=Q, D=1)\n",
    "\n",
    "model = pyGPs.GPR()\n",
    "model.setData(X_CO2_train, Y_CO2_train)\n",
    "model.setPrior(mean=pyGPs.mean.Zero(), kernel=kernel)\n",
    "initSMhypers(model, X_CO2_train, Y_CO2_train)\n",
    "\n",
    "model.setOptimizer('Minimize', num_restarts=10)\n",
    "model.getPosterior()\n",
    "model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean, var, _, _, _ = model.predict(X_CO2_test)\n",
    "layer_plot(X_CO2_test[:, 0], mean[:, 0], np.sqrt(var[:, 0]))\n",
    "plt.plot(X_CO2_test, Y_CO2_test, c='black', label='True Values', linewidth=3)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still terrible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: Experiment with the parameter Q until you get good results above. \n",
    "# What is the smallest value giving good prediction? Compare with what [Adams, Wilson] report.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining the Spectral Density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the parameters that were learned. This determines a mixture of gaussians: a collection of weights, proportional to which we choose a gaussian with given means and variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = np.exp(model.covfunc.hyp[:Q])\n",
    "spectral_means = np.exp(np.reshape(model.covfunc.hyp[Q:Q + Q * 1], (1, Q)))\n",
    "spectral_variances = np.exp(2 * np.reshape(model.covfunc.hyp[Q + Q * 1:], (1, Q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: By sampling from the gaussian mixture model, draw a histogram of the spectral density.\n",
    "# If necessary, draw one histogram for the most likely component, and a separate one for the others (if one\n",
    "# component is too likely, the others will not get picked often enough for you to estimate well). If necessary,\n",
    "# plot on a log scale to make the differences clear. Compare with Figure 1(b) of [Adams, Wilson].\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
