{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Time Series Analysis\n",
    "\n",
    "## Week 10: Sparse Gaussian Processes Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Places where you are supposed to fill in code are marked\n",
    "\n",
    "    #\n",
    "    # TODO: some instructions\n",
    "    # \n",
    "    \n",
    "The rest of the code we will run and discuss if time permits, otherwise try it out at home and try to answer the questions mentioned in the text boxes for yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please turn in the code before 12/5/2018 5:20pm. \n",
    "\n",
    "### Your work will be evaluated based on the code and plots. You don't need to write down your answers to other questions in the text blocks, just think them over.\n",
    "\n",
    "### Title your submission file `lab10-student-[YOUR NET ID].ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import GPy\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Pseudo-Dataset Size Requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uniform_samples(x_min, x_max, n_samples, f, noise_scale):\n",
    "    \"\"\"Generates f(x) + noise for x uniformly distributed in [x_min, x_max].\"\"\"\n",
    "    X = np.random.uniform(x_min, x_max, size=(n_samples, 1))\n",
    "    Y = f(X) + np.random.normal(scale=noise_scale, size=(n_samples, 1))\n",
    "    return X, Y\n",
    "\n",
    "def gapped_samples(x_min, x_max, n_samples, f, noise_scale):\n",
    "    \"\"\"Generates f(x) + noise for x uniformly distributed in [x_min, x_max] missing middle third.\"\"\"\n",
    "    X = np.array(\n",
    "        list(np.random.uniform(x_min, x_min + (x_max - x_min) / 3.0, size=(n_samples / 2, 1))) + \n",
    "        list(np.random.uniform(x_min + 2.0 * (x_max - x_min) / 3.0, x_max, size=(n_samples / 2, 1))))\n",
    "    Y = f(X) + np.random.normal(scale=noise_scale, size=(n_samples, 1))\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = uniform_samples(-20.0, 20.0, 100, np.sin, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel = GPy.kern.RBF(input_dim=1, variance=1., lengthscale=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, here is an example of \"naive\" GP regression, as we studied in the last lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_reg = GPy.models.GPRegression(X, Y, kernel)\n",
    "_ = m_reg.optimize()\n",
    "_ = m_reg.plot(plot_density=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is an example of FITC regression, where the `num_inducing` parameter controls how many points are used in the pseudo-dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_sparse = GPy.models.SparseGPRegression(X, Y, kernel, num_inducing=10)\n",
    "m_sparse.inference_method=GPy.inference.latent_function_inference.FITC()\n",
    "_ = m_sparse.optimize()\n",
    "_ = m_sparse.plot(plot_density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: Try varying num_inducing in the example above to identify how many samples are needed before the quality\n",
    "# of the fit with FITC is similar to that with the naive method. Show one plot where there are still not enough\n",
    "# pseudo-data points, and one where the results are similar.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_X = np.linspace(-20.0, 20.0, 400).reshape(400, 1)\n",
    "\n",
    "def model_distance(model_ref, model_test):\n",
    "    ref_out = model_ref.predict(test_X)[0]\n",
    "    test_out = model_test.predict(test_X)[0]\n",
    "    return np.sum((ref_out - test_out) ** 2) / np.sum(ref_out ** 2)\n",
    "\n",
    "print model_distance(m_reg, m_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: Let's make the above result a little more quantitative. The function model_distance gives a numerical relative\n",
    "# difference (in L^2 norm) between the outputs of two models. Make a plot of this number vs. the pseudo-dataset size \n",
    "# for a reasonable range of sizes.\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Efficiency Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple way to measure how long a piece of Python code takes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = uniform_samples(-20.0, 20.0, 1000, np.sin, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "m_reg = GPy.models.GPRegression(X, Y, kernel)\n",
    "_ = m_reg.optimize()\n",
    "end = time.time()\n",
    "print 'Naive method:', end - start, 'seconds'\n",
    "\n",
    "start = time.time()\n",
    "m_sparse = GPy.models.SparseGPRegression(X, Y, kernel, num_inducing=10)\n",
    "m_sparse.inference_method=GPy.inference.latent_function_inference.FITC()\n",
    "_ = m_sparse.optimize()\n",
    "end = time.time()\n",
    "print 'Sparse method:', end - start, 'seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we weren't lying to you---the sparse method is much faster. But how much? Let's investigate the runtime asymptotics we claimed in class.\n",
    "\n",
    "There are two relevant numbers: $N$ is the number of data points in the original set, $N = 1000$ above, and $M$ is the number of pseudo-datapoints we use, $M = 10$ above. The naive method is supposed to run in time $O(N^3)$, while the FITC method is supposed to run in time $O(NM^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: Study the dependence of the runtimes of the two methods on N: fix some reasonable M, vary N, for each N \n",
    "# drawing several sets of samples as above, and measure how long it takes to optimize each of the two models. For each\n",
    "# N and each model, take the mean of the times you measure, and plot these. If you want, try to confirm the power\n",
    "# scaling on a log-log plot. (Timing studies are hard and this is a very naive way to measure code execution, so don't\n",
    "# worry if it doesn't look perfect.)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: Just for the FITC method, study the dependence of the runtime on M: fix some reasonable N, vary M, and proceed\n",
    "# as above.\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
